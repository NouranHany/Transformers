{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Overview\n* Trained a model using the cropped images obtained from script crop right noise\n* Increasing the size of data by doing augmentation is not yet implemented","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#Deep Learning\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport os\nimport cv2\nimport glob\nimport skimage.io as io\nfrom skimage.color import rgb2gray\n\n#Data Visualizations\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-03-24T16:17:34.355213Z","iopub.execute_input":"2022-03-24T16:17:34.355574Z","iopub.status.idle":"2022-03-24T16:17:34.368790Z","shell.execute_reply.started":"2022-03-24T16:17:34.355544Z","shell.execute_reply":"2022-03-24T16:17:34.367890Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainData = []\ntrainLabels = []\n\ndirectory=\"/kaggle/input/cropped-data/cropped_characters/*/*\"\n\npaths = glob.glob(directory)\nfor path in paths:\n    img = io.imread(path)\n    trainData.append(img)\n    img_label = path.split('/')[-2]\n    trainLabels.append(img_label)\n\ntrainData = np.array(trainData)\ntrainLabels = np.array(trainLabels)\n\nprint(trainLabels.shape)\nprint(trainData.shape)\nprint(trainData[0].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n\ndef change_size(image):\n    img = array_to_img(image, scale=False) #returns PIL Image\n    img = img.resize((75, 75)) #resize image\n    arr = img_to_array(img) #convert back to array\n    return arr.astype(np.float64)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T16:17:47.697757Z","iopub.execute_input":"2022-03-24T16:17:47.698075Z","iopub.status.idle":"2022-03-24T16:17:47.703845Z","shell.execute_reply.started":"2022-03-24T16:17:47.698047Z","shell.execute_reply":"2022-03-24T16:17:47.702948Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2) # set validation split\n\ntrain_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/cropped-data/cropped_characters',\n    target_size=(75, 75),\n    batch_size=20,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nvalidation_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/cropped-data/cropped_characters', # same directory as training data\n    target_size=(75, 75),\n    batch_size=20,\n    class_mode='categorical',\n    subset='validation') # set as validation data","metadata":{"execution":{"iopub.status.busy":"2022-03-24T16:17:49.444450Z","iopub.execute_input":"2022-03-24T16:17:49.444773Z","iopub.status.idle":"2022-03-24T16:17:51.570686Z","shell.execute_reply.started":"2022-03-24T16:17:49.444746Z","shell.execute_reply":"2022-03-24T16:17:51.569401Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"We split the data into the train and validation sets. Here is the distribution of the split data.","metadata":{}},{"cell_type":"code","source":"sns.barplot(['train', 'valid'], [train_generator.n, validation_generator.n])","metadata":{"execution":{"iopub.status.busy":"2022-03-24T16:18:07.580030Z","iopub.execute_input":"2022-03-24T16:18:07.580366Z","iopub.status.idle":"2022-03-24T16:18:07.714495Z","shell.execute_reply.started":"2022-03-24T16:18:07.580332Z","shell.execute_reply":"2022-03-24T16:18:07.713603Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(tf.keras.applications.resnet50.ResNet50(input_shape = (75, 75, 3), \n                                include_top = False, \n                                weights = 'imagenet'))\n\nmodel.add(L.Flatten())\nmodel.add(L.Dense(128, activation='relu'))\nmodel.add(L.Dense(38, activation='softmax'))\n\nmodel.compile(optimizer=keras.optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n#Do not use default learning rate since it is too high!","metadata":{"execution":{"iopub.status.busy":"2022-03-24T16:18:11.826694Z","iopub.execute_input":"2022-03-24T16:18:11.827028Z","iopub.status.idle":"2022-03-24T16:18:17.381029Z","shell.execute_reply.started":"2022-03-24T16:18:11.826998Z","shell.execute_reply":"2022-03-24T16:18:17.380250Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for layer in model.layers[0].layers:\n    if layer.name == 'conv5_block1_0_conv':\n        break\n    layer.trainable=False","metadata":{"execution":{"iopub.status.busy":"2022-03-24T16:18:20.623101Z","iopub.execute_input":"2022-03-24T16:18:20.623429Z","iopub.status.idle":"2022-03-24T16:18:20.634999Z","shell.execute_reply.started":"2022-03-24T16:18:20.623399Z","shell.execute_reply":"2022-03-24T16:18:20.634274Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator, epochs=5, \n            validation_data=validation_generator,\n            validation_steps=50,\n          steps_per_epoch=train_generator.n//train_generator.batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T16:18:22.713396Z","iopub.execute_input":"2022-03-24T16:18:22.713720Z","iopub.status.idle":"2022-03-24T16:24:37.356150Z","shell.execute_reply.started":"2022-03-24T16:18:22.713690Z","shell.execute_reply":"2022-03-24T16:24:37.355286Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history.history[     'accuracy' ]\nval_acc  = history.history[ 'val_accuracy' ]\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.legend(['train', 'test'])\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )\nplt.legend(['train', 'test'])","metadata":{"execution":{"iopub.status.busy":"2022-03-24T16:26:59.664419Z","iopub.execute_input":"2022-03-24T16:26:59.664738Z","iopub.status.idle":"2022-03-24T16:26:59.957417Z","shell.execute_reply.started":"2022-03-24T16:26:59.664709Z","shell.execute_reply":"2022-03-24T16:26:59.956406Z"},"trusted":true},"execution_count":25,"outputs":[]}]}