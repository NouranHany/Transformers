{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Overview\n","* Trained a model using the cropped images obtained from script crop right noise\n","* Increasing the size of data by doing augmentation is not yet implemented"]},{"cell_type":"markdown","metadata":{},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T10:55:09.825209Z","iopub.status.busy":"2022-03-25T10:55:09.824940Z","iopub.status.idle":"2022-03-25T10:55:09.873172Z","shell.execute_reply":"2022-03-25T10:55:09.872526Z","shell.execute_reply.started":"2022-03-25T10:55:09.825176Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","#Deep Learning\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers as L\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from skimage.transform import resize\n","\n","import os\n","import cv2\n","import glob\n","import skimage.io as io\n","import pickle\n","from skimage.color import rgb2gray\n","\n","#Data Visualizations\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T09:32:48.846242Z","iopub.status.busy":"2022-03-25T09:32:48.845541Z","iopub.status.idle":"2022-03-25T09:33:31.841812Z","shell.execute_reply":"2022-03-25T09:33:31.841005Z","shell.execute_reply.started":"2022-03-25T09:32:48.846208Z"},"trusted":true},"outputs":[{"ename":"ValueError","evalue":"Could not find a format to read the specified file in ImageMode.single_image mode","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3316/2721307976.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mimgBlurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGAUSSIAN_SMOOTH_FILTER_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mimgThreshValue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgBlurred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Python310\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imread'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Python310\\lib\\site-packages\\skimage\\io\\manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m                                (plugin, kind))\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Python310\\lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mC:\\Python310\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m         )\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mimopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ri\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Python310\\lib\\site-packages\\imageio\\core\\imopen.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, uri, io_mode, plugin, search_legacy_only, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m                         \u001b[1;31m# type of error raised to IOError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                         \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mplugin_instance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Python310\\lib\\site-packages\\imageio\\core\\imopen.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, uri, io_mode, plugin, search_legacy_only, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                     \u001b[0mplugin_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLegacyPlugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[0mplugin_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Python310\\lib\\site-packages\\imageio\\core\\imopen.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, request, plugin_manager, uri, io_mode, format)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mplugin\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m             \u001b[0mmodename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMODENAMES\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    217\u001b[0m                 \u001b[1;34m\"Could not find a format to read the specified file\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                 \u001b[1;34m\" in %s mode\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmodename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: Could not find a format to read the specified file in ImageMode.single_image mode"]}],"source":["trainData = []\n","trainLabels = []\n","\n","directory=\"./cropped_characters/*/*\"\n","\n","paths = glob.glob(directory)\n","count= 0\n","for path in paths:\n","    img = io.imread(path)\n","    imgBlurred = cv2.GaussianBlur(img, GAUSSIAN_SMOOTH_FILTER_SIZE, 0)\n","    imgThreshValue = cv2.threshold(imgBlurred, 0, 255, cv2.THRESH_OTSU)[1]\n","    imgPadded = sideBorder(imgThreshValue, 1)\n","    \n","    trainData.append(imgPadded)\n","    img_label = path.split('/')[-2]\n","    trainLabels.append(img_label)\n","\n","trainData = np.array(trainData)\n","trainLabels = np.array(trainLabels)\n","\n","print(trainLabels.shape)\n","print(trainData.shape)\n","print(trainData[0].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Padding\n","\n","\n","\n","\n","# Blur\n","\n","# Thresholding\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T09:33:31.844180Z","iopub.status.busy":"2022-03-25T09:33:31.843463Z","iopub.status.idle":"2022-03-25T09:33:31.850373Z","shell.execute_reply":"2022-03-25T09:33:31.849418Z","shell.execute_reply.started":"2022-03-25T09:33:31.844142Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n","\n","def change_size(image):\n","    img = array_to_img(image, scale=False) #returns PIL Image\n","    img = img.resize((150, 150)) #resize image\n","    arr = img_to_array(img) #convert back to array\n","    return arr.astype(np.float64)"]},{"cell_type":"markdown","metadata":{},"source":["## Apply augmentation\n","- rotation, shifts, brightness change"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T11:12:07.900003Z","iopub.status.busy":"2022-03-25T11:12:07.899695Z","iopub.status.idle":"2022-03-25T11:12:10.774630Z","shell.execute_reply":"2022-03-25T11:12:10.773828Z","shell.execute_reply.started":"2022-03-25T11:12:07.899971Z"},"trusted":true},"outputs":[],"source":["# The flow_from_directory() method allows you to read the images directly from the directory and augment them while the neural network model is learning on the training data.\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","    shear_range=0.2,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","#     zoom_range=0.2,\n","    rotation_range=30,\n","    validation_split=0.2) # set validation split\n","\n","train_generator = train_datagen.flow_from_directory(\n","    './cropped_characters',\n","    target_size=(150, 150),\n","    batch_size=128,\n","    class_mode='categorical',\n","    subset='training') # set as training data\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    './cropped_characters', # same directory as training data\n","    target_size=(150, 150),\n","    batch_size=20,\n","    class_mode='categorical',\n","    subset='validation') # set as validation data"]},{"cell_type":"markdown","metadata":{},"source":["We split the data into the train and validation sets. Here is the distribution of the split data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T09:18:25.144778Z","iopub.status.busy":"2022-03-25T09:18:25.144470Z","iopub.status.idle":"2022-03-25T09:18:25.369518Z","shell.execute_reply":"2022-03-25T09:18:25.368631Z","shell.execute_reply.started":"2022-03-25T09:18:25.144737Z"},"trusted":true},"outputs":[],"source":["sns.barplot(['train', 'valid'], [train_generator.n, validation_generator.n])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T11:15:01.277021Z","iopub.status.busy":"2022-03-25T11:15:01.276289Z","iopub.status.idle":"2022-03-25T11:15:01.358678Z","shell.execute_reply":"2022-03-25T11:15:01.357297Z","shell.execute_reply.started":"2022-03-25T11:15:01.276984Z"},"trusted":true},"outputs":[],"source":["# model = Sequential()\n","\n","# model.add(tf.keras.applications.resnet50.ResNet50(input_shape = (150, 150, 3), \n","#                                 include_top = False, \n","#                                 weights = 'imagenet'))\n","\n","# model.add(L.Flatten())\n","# model.add(tf.keras.layers.Dropout(0.2))\n","# model.add(L.Dense(256, activation='relu'))\n","# model.add(tf.keras.layers.Dropout(0.2))\n","# model.add(L.Dense(128, activation='relu'))\n","# model.add(L.Dense(38, activation='softmax'))\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2), \n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n","    tf.keras.layers.MaxPooling2D(2,2),\n","    \n","    # Flatten the results to feed into a DNN\n","    tf.keras.layers.Flatten(), \n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(256, activation='relu'),\n","    tf.keras.layers.Dense(128, activation='relu'), \n","    \n","    tf.keras.layers.Dense(38, activation='softmax')  \n","])\n","\n","model.compile(optimizer=keras.optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","#Do not use default learning rate since it is too high!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T12:27:31.856399Z","iopub.status.busy":"2022-03-25T12:27:31.856130Z","iopub.status.idle":"2022-03-25T12:27:31.861403Z","shell.execute_reply":"2022-03-25T12:27:31.860485Z","shell.execute_reply.started":"2022-03-25T12:27:31.856371Z"},"trusted":true},"outputs":[],"source":["class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        # Check accuracy\n","        if(logs.get('accuracy') > 90):\n","            # Stop if threshold is met\n","            print(\"\\naccuracy of training is bigger than 90!\")\n","            self.model.stop_training = True\n","\n","# Instantiate class\n","callbacks = myCallback()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T11:15:09.433210Z","iopub.status.busy":"2022-03-25T11:15:09.432953Z","iopub.status.idle":"2022-03-25T11:15:09.436926Z","shell.execute_reply":"2022-03-25T11:15:09.435921Z","shell.execute_reply.started":"2022-03-25T11:15:09.433181Z"},"trusted":true},"outputs":[],"source":["# for layer in model.layers[0].layers:\n","#     if layer.name == 'conv5_block1_0_conv':\n","#         break\n","#     layer.trainable=False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T11:15:27.421132Z","iopub.status.busy":"2022-03-25T11:15:27.420462Z","iopub.status.idle":"2022-03-25T12:08:13.851131Z","shell.execute_reply":"2022-03-25T12:08:13.850345Z","shell.execute_reply.started":"2022-03-25T11:15:27.421083Z"},"trusted":true},"outputs":[],"source":["history = model.fit(train_generator, epochs=20, \n","            validation_data=validation_generator,\n","            steps_per_epoch=train_generator.n//train_generator.batch_size,\n","            validation_steps=validation_generator.n//validation_generator.batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T12:08:52.951819Z","iopub.status.busy":"2022-03-25T12:08:52.951555Z","iopub.status.idle":"2022-03-25T12:08:53.399759Z","shell.execute_reply":"2022-03-25T12:08:53.398291Z","shell.execute_reply.started":"2022-03-25T12:08:52.951792Z"},"trusted":true},"outputs":[],"source":["#-----------------------------------------------------------\n","# Retrieve a list of list results on training and test data\n","# sets for each training epoch\n","#-----------------------------------------------------------\n","acc      = history.history[     'accuracy' ]\n","val_acc  = history.history[ 'val_accuracy' ]\n","loss     = history.history[    'loss' ]\n","val_loss = history.history['val_loss' ]\n","\n","epochs   = range(len(acc)) # Get number of epochs\n","\n","#------------------------------------------------\n","# Plot training and validation accuracy per epoch\n","#------------------------------------------------\n","plt.plot  ( epochs,     acc )\n","plt.plot  ( epochs, val_acc )\n","plt.title ('Training and validation accuracy')\n","plt.legend(['train', 'test'])\n","plt.figure()\n","\n","#------------------------------------------------\n","# Plot training and validation loss per epoch\n","#------------------------------------------------\n","plt.plot  ( epochs,     loss )\n","plt.plot  ( epochs, val_loss )\n","plt.title ('Training and validation loss'   )\n","plt.legend(['train', 'test'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T12:13:43.062129Z","iopub.status.busy":"2022-03-25T12:13:43.061435Z","iopub.status.idle":"2022-03-25T12:13:44.883822Z","shell.execute_reply":"2022-03-25T12:13:44.883103Z","shell.execute_reply.started":"2022-03-25T12:13:43.062072Z"},"trusted":true},"outputs":[],"source":["# save the model to disk\n","dirpath = 'char_detect_model'\n","\n","model.save('char_detect_model')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T12:30:27.429968Z","iopub.status.busy":"2022-03-25T12:30:27.429705Z","iopub.status.idle":"2022-03-25T12:30:28.002625Z","shell.execute_reply":"2022-03-25T12:30:28.001688Z","shell.execute_reply.started":"2022-03-25T12:30:27.429940Z"},"trusted":true},"outputs":[],"source":["model = keras.models.load_model('char_detect_model')\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T12:30:31.953940Z","iopub.status.busy":"2022-03-25T12:30:31.953434Z"},"trusted":true},"outputs":[],"source":["history = model.fit(train_generator, epochs=40, \n","            validation_data=validation_generator,\n","            steps_per_epoch=train_generator.n//train_generator.batch_size,\n","            validation_steps=validation_generator.n//validation_generator.batch_size, callbacks=[callbacks])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T10:56:36.938365Z","iopub.status.busy":"2022-03-25T10:56:36.937785Z","iopub.status.idle":"2022-03-25T10:56:36.946816Z","shell.execute_reply":"2022-03-25T10:56:36.946028Z","shell.execute_reply.started":"2022-03-25T10:56:36.938322Z"},"trusted":true},"outputs":[],"source":["labels = os.listdir('../input/croppeddata/cropped_characters')\n","\n","def predict(img, model, labels):\n","    img = resize(img, (150,150,3), anti_aliasing=True)\n","    img = np.expand_dims(img, axis=0)\n","    \n","    preds = model.predict(img)\n","    return labels[np.argmax(preds)]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T10:55:29.967698Z","iopub.status.busy":"2022-03-25T10:55:29.967441Z","iopub.status.idle":"2022-03-25T10:55:29.973602Z","shell.execute_reply":"2022-03-25T10:55:29.972140Z","shell.execute_reply.started":"2022-03-25T10:55:29.967670Z"},"trusted":true},"outputs":[],"source":["print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T10:18:59.758569Z","iopub.status.busy":"2022-03-25T10:18:59.757800Z","iopub.status.idle":"2022-03-25T10:18:59.763791Z","shell.execute_reply":"2022-03-25T10:18:59.762902Z","shell.execute_reply.started":"2022-03-25T10:18:59.758533Z"},"trusted":true},"outputs":[],"source":["#!pip install imutils"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T10:59:04.388416Z","iopub.status.busy":"2022-03-25T10:59:04.387846Z","iopub.status.idle":"2022-03-25T10:59:04.396588Z","shell.execute_reply":"2022-03-25T10:59:04.395851Z","shell.execute_reply.started":"2022-03-25T10:59:04.388377Z"},"trusted":true},"outputs":[],"source":["#import pytesseract\n","from imutils import paths\n","import argparse\n","import imutils\n","import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from skimage.segmentation import clear_border\n","import numpy as np\n","import skimage \n","from PIL import Image\n","#from imutils.perspective import four_point_transform\n","%matplotlib inline"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T11:00:52.838605Z","iopub.status.busy":"2022-03-25T11:00:52.838038Z","iopub.status.idle":"2022-03-25T11:00:52.851388Z","shell.execute_reply":"2022-03-25T11:00:52.850580Z","shell.execute_reply.started":"2022-03-25T11:00:52.838567Z"},"trusted":true},"outputs":[],"source":["# module level variables ##########################################################################\n","GAUSSIAN_SMOOTH_FILTER_SIZE = (5, 5)\n","ADAPTIVE_THRESH_BLOCK_SIZE = 19\n","ADAPTIVE_THRESH_WEIGHT = 9\n","\n","###################################################################################################\n","def preprocess(imgOriginal):\n","    imgSaturation, imgGrayscale = extractValue(imgOriginal)\n","\n","    imgMaxContrastGrayscale = maximizeContrast(imgGrayscale)\n","\n","    imgBlurred = cv2.GaussianBlur(imgMaxContrastGrayscale, GAUSSIAN_SMOOTH_FILTER_SIZE, 0)\n","\n","    imgThreshValue = cv2.threshold(imgBlurred, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n","    imgThreshSaturation = cv2.threshold(imgSaturation, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n","\n","    # plt.imshow(imgBlurred,cmap='gray')\n","    # plt.show()\n","    # plt.imshow(imgThreshValue,cmap='gray')\n","    # plt.show()\n","\n","    # plt.imshow(imgSaturation,cmap='gray')\n","    # plt.show()\n","    # plt.imshow(imgThreshSaturation,cmap='gray')\n","    # plt.show()\n","\n","    #imgThresh = cv2.adaptiveThreshold(imgBlurred, 255.0, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, ADAPTIVE_THRESH_BLOCK_SIZE, ADAPTIVE_THRESH_WEIGHT)\n","    \n","    return imgGrayscale, (imgThreshValue & (255 - imgThreshSaturation))\n","# end function\n","\n","def preprocess2(imgOriginal):\n","    _, imgGrayscale = extractValue(imgOriginal)\n","\n","    imgBlurred = cv2.GaussianBlur(imgGrayscale, GAUSSIAN_SMOOTH_FILTER_SIZE, 0)\n","\n","    imgThreshValue = cv2.threshold(imgBlurred, 0, 255, cv2.THRESH_OTSU)[1]\n","\n","    # plt.imshow(imgBlurred,cmap='gray')\n","    # plt.show()\n","    # plt.imshow(imgThreshValue,cmap='gray')\n","    # plt.show()\n","\n","    # plt.imshow(imgSaturation,cmap='gray')\n","    # plt.show()\n","    # plt.imshow(imgThreshSaturation,cmap='gray')\n","    # plt.show()\n","\n","    #imgThresh = cv2.adaptiveThreshold(imgBlurred, 255.0, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, ADAPTIVE_THRESH_BLOCK_SIZE, ADAPTIVE_THRESH_WEIGHT)\n","    \n","    return imgThreshValue\n","# end function\n","\n","###################################################################################################\n","def extractValue(imgOriginal):\n","    height, width, numChannels = imgOriginal.shape\n","\n","    imgHSV = np.zeros((height, width, 3), np.uint8)\n","\n","    imgHSV = cv2.cvtColor(imgOriginal, cv2.COLOR_BGR2HSV)\n","\n","    imgHue, imgSaturation, imgValue = cv2.split(imgHSV)\n","\n","    return imgSaturation, imgValue\n","# end function\n","\n","###################################################################################################\n","def maximizeContrast(imgGrayscale):\n","\n","    height, width = imgGrayscale.shape\n","\n","    imgTopHat = np.zeros((height, width, 1), np.uint8)\n","    imgBlackHat = np.zeros((height, width, 1), np.uint8)\n","\n","    structuringElement = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n","\n","    imgTopHat = cv2.morphologyEx(imgGrayscale, cv2.MORPH_TOPHAT, structuringElement)\n","    imgBlackHat = cv2.morphologyEx(imgGrayscale, cv2.MORPH_BLACKHAT, structuringElement)\n","\n","    imgGrayscalePlusTopHat = cv2.add(imgGrayscale, imgTopHat)\n","    imgGrayscalePlusTopHatMinusBlackHat = cv2.subtract(imgGrayscalePlusTopHat, imgBlackHat)\n","\n","    return imgGrayscalePlusTopHatMinusBlackHat\n","# end function"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T11:00:56.333111Z","iopub.status.busy":"2022-03-25T11:00:56.332460Z","iopub.status.idle":"2022-03-25T11:00:56.341001Z","shell.execute_reply":"2022-03-25T11:00:56.339040Z","shell.execute_reply.started":"2022-03-25T11:00:56.333073Z"},"trusted":true},"outputs":[],"source":["def order_points(pts):\n","\t# initialzie a list of coordinates that will be ordered\n","\t# such that the first entry in the list is the top-left,\n","\t# the second entry is the top-right, the third is the\n","\t# bottom-right, and the fourth is the bottom-left\n","\trect = np.zeros((4, 2), dtype = \"float32\")\n","\t# the top-left point will have the smallest sum, whereas\n","\t# the bottom-right point will have the largest sum\n","\ts = pts.sum(axis = 1)\n","\trect[0] = pts[np.argmin(s)]\n","\trect[2] = pts[np.argmax(s)]\n","\t# now, compute the difference between the points, the\n","\t# top-right point will have the smallest difference,\n","\t# whereas the bottom-left will have the largest difference\n","\tdiff = np.diff(pts, axis = 1)\n","\trect[1] = pts[np.argmin(diff)]\n","\trect[3] = pts[np.argmax(diff)]\n","\t# return the ordered coordinates\n","\treturn rect"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T11:01:00.536251Z","iopub.status.busy":"2022-03-25T11:01:00.535661Z","iopub.status.idle":"2022-03-25T11:01:00.547040Z","shell.execute_reply":"2022-03-25T11:01:00.545914Z","shell.execute_reply.started":"2022-03-25T11:01:00.536206Z"},"trusted":true},"outputs":[],"source":["def four_point_transform(image, pts):\n","\t# obtain a consistent order of the points and unpack them\n","\t# individually\n","\trect = order_points(pts)\n","\t(tl, tr, br, bl) = rect\n","\t# compute the width of the new image, which will be the\n","\t# maximum distance between bottom-right and bottom-left\n","\t# x-coordiates or the top-right and top-left x-coordinates\n","\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n","\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n","\tmaxWidth = max(int(widthA), int(widthB))\n","\t# compute the height of the new image, which will be the\n","\t# maximum distance between the top-right and bottom-right\n","\t# y-coordinates or the top-left and bottom-left y-coordinates\n","\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n","\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n","\tmaxHeight = max(int(heightA), int(heightB))\n","\t# now that we have the dimensions of the new image, construct\n","\t# the set of destination points to obtain a \"birds eye view\",\n","\t# (i.e. top-down view) of the image, again specifying points\n","\t# in the top-left, top-right, bottom-right, and bottom-left\n","\t# order\n","\tdst = np.array([\n","\t\t[0, 0],\n","\t\t[maxWidth - 1, 0],\n","\t\t[maxWidth - 1, maxHeight - 1],\n","\t\t[0, maxHeight - 1]], dtype = \"float32\")\n","\t# compute the perspective transform matrix and then apply it\n","\tM = cv2.getPerspectiveTransform(rect, dst)\n","\twarped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n","\t# return the warped image\n","\treturn warped"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T11:01:02.247645Z","iopub.status.busy":"2022-03-25T11:01:02.247392Z","iopub.status.idle":"2022-03-25T11:01:02.258069Z","shell.execute_reply":"2022-03-25T11:01:02.256998Z","shell.execute_reply.started":"2022-03-25T11:01:02.247618Z"},"trusted":true},"outputs":[],"source":["def contourApprox(imgOriginal, cnts):\n","\t# initialize a contour that corresponds to the receipt outline\n","\treceiptCnt = []\n","\tfirstContour = False\n","\tfirstArea = 0\n","\tfirstPeri = 0\n","\n","\t# loop over the contours\n","\tfor c in cnts:\n","\t\t# approximate the contour\n","\t\tperi = cv2.arcLength(c, True) + 0.01\n","\t\tapprox = cv2.approxPolyDP(c, 0.05 * peri, True)\n","\n","\t\tarea = cv2.contourArea(approx) + 0.01\n","\n","\t\tdrawnContour = imgOriginal.copy()\n","\t\tcv2.drawContours(drawnContour, [approx], -1, (0, 255, 0), 2)\n","# \t\tplt.imshow(drawnContour)\n","# \t\tplt.show()\n","\t\t\n","\t\tif area < 3000:\n","\t\t\tbreak\n","\n","\t\t# if our approximated contour has four points, then we can\n","\t\t# assume we have found the outline of the receipt\n","\t\tif len(approx) == 4 and (not firstContour or (firstPeri / peri < 1.4 and firstPeri / peri > 0.7 and firstArea / area < 1.4 and firstArea / area > 0.7)):\n","\t\t\treceiptCnt.append(approx)\n","\t\t\tif firstContour:\n","\t\t\t\t break\n","\t\t\tfirstContour = True\n","\t\t\tfirstArea = area\n","\t\t\tfirstPeri = peri\n","\t\t\t\n","\t\telse:\n","\t\t\tapprox = cv2.convexHull(approx)\n","\t\t\tperi = cv2.arcLength(approx, True) + 0.01\n","\t\t\tarea = cv2.contourArea(approx) + 0.01\n","\t\t\tif len(approx) == 4 and (not firstContour or (firstPeri / peri < 1.4 and firstPeri / peri > 0.7 and firstArea / area < 1.4 and firstArea / area > 0.7)):\n","\t\t\t\treceiptCnt.append(approx)\n","\t\t\t\tif firstContour:\n","\t\t\t\t\tbreak\n","\t\t\t\tfirstContour = True\n","\t\t\t\tfirstArea = area\n","\t\t\t\tfirstPeri = peri\n","\t\t\t\tbreak\t\t\n","\t# if the receipt contour is empty then our script could not find the\n","\t# outline and we should be notified\n","\treturn receiptCnt"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T11:01:04.553703Z","iopub.status.busy":"2022-03-25T11:01:04.553134Z","iopub.status.idle":"2022-03-25T11:01:04.559279Z","shell.execute_reply":"2022-03-25T11:01:04.558273Z","shell.execute_reply.started":"2022-03-25T11:01:04.553663Z"},"trusted":true},"outputs":[],"source":["def showApprox(imgOriginal, thresh, receiptCnt):\n","    cv2.drawContours(imgOriginal, [receiptCnt], -1, (0, 255, 0), 2)\n","    #print(output[1])\n","    #plt.imshow(imgOriginal)\n","    #plt.show()\n","    rect_coor = np.array(receiptCnt.reshape(4,2))\n","    img = four_point_transform(imgOriginal, rect_coor)\n","    #print(img.shape)\n","    #img_new = add_margin(img, 5, 10, 0, 10)\n","    final_img = preprocess2(img)\n","#     plt.imshow(final_img, cmap=\"gray\")\n","#     plt.show()\n","    return (final_img,img)\n","    #print(f\"boundaries = {receiptCnt.reshape(4, 2)}\")\n"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T11:01:07.927827Z","iopub.status.busy":"2022-03-25T11:01:07.927215Z","iopub.status.idle":"2022-03-25T11:01:07.943393Z","shell.execute_reply":"2022-03-25T11:01:07.942469Z","shell.execute_reply.started":"2022-03-25T11:01:07.927787Z"},"trusted":true},"outputs":[],"source":["def CutLetters(img,rgb_img, count):\n","    height, width = img.shape\n","    windowWidthR = int(0.18 * width * count)\n","    windowWidthL = int(0.12 * width * count)\n","    windowWidth = windowWidthR\n","    if count == 2:\n","        windowWidthR = windowWidthL\n","    startRatio = int(0.1 * windowWidth)\n","    windowHeight = img.shape[0]\n","    marginWidth = int(windowWidth * 0.05)\n","    stepSize = 8\n","    GroupSize = 8\n","    lowerBlackLimit = 0.07\n","    upperBlackLimit = 0.9\n","\n","    Letters = []\n","    Letters_imgs = []\n","    Letters_imgs_thresh = []\n","    for i in range(0, width - (windowWidth), stepSize * GroupSize):\n","\n","        Group = []\n","        for j in range(i, min(i + stepSize * GroupSize, width - (windowWidth)), stepSize):\n","            #plt.imshow(img[:, j:j+windowWidth],cmap='gray')\n","            #plt.show()\n","            if j <= width/2:\n","                windowWidth = windowWidthL\n","            else:\n","                windowWidth = windowWidthR\n","\n","            blackCountMarginL = marginWidth * height  - np.count_nonzero(img[:, j : j+marginWidth])\n","            blackCountMarginR = marginWidth * height  - np.count_nonzero(img[:, j+windowWidth-marginWidth : j+windowWidth])\n","            blackCountInner = (windowWidth - 2 * startRatio) * height - np.count_nonzero(img[:, j+startRatio : j+windowWidth-startRatio])\n","            \n","            #print(blackCountMarginL, marginWidth * height)\n","            #print(blackCountMarginR, marginWidth * height)\n","            #print(blackCountInner, (windowWidth - 2 * marginWidth) * height)\n","            #and blackCountMarginR < 0.2 * marginWidth * height \\\n","\n","            if blackCountMarginL < 0.25 * marginWidth * height and blackCountMarginR < 0.17 * marginWidth * height and blackCountInner > lowerBlackLimit * (windowWidth - 2 * startRatio) * height \\\n","                and blackCountInner < upperBlackLimit * (windowWidth - 2 * startRatio) * height:\n","                Group.append((blackCountInner, j))\n","        if len(Group) > 0:\n","            max_G = max(Group)[1]\n","            if len(Letters) == 0 or len(Letters) > 0 and max_G - Letters[-1] > 21:\n","                Letters.append(max_G)\n","              # rect_coord = [rgb_img[0][0],rgb_img[0][-1],max(Group)[1],max(Group)[1]+windowWidth]\n","              # rect_coord = np.array(rect_coord,dtype='int32')\n","                rgb2_img = rgb_img[:, max_G:max_G+windowWidth]\n","                Letters_imgs.append((rgb2_img, max_G))\n","                #               plt.imshow(rgb2_img)\n","                thresh_img = img[:, max_G:max_G+windowWidth]\n","                Letters_imgs_thresh.append((thresh_img, max_G))\n","              #plt.imshow(img[:, max(Group)[1]:max(Group)[1]+windowWidth],cmap='gray')\n","              #plt.show()\n","\n","    return Letters_imgs,Letters_imgs_thresh\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T11:01:11.043337Z","iopub.status.busy":"2022-03-25T11:01:11.042825Z","iopub.status.idle":"2022-03-25T11:01:11.050490Z","shell.execute_reply":"2022-03-25T11:01:11.049466Z","shell.execute_reply.started":"2022-03-25T11:01:11.043281Z"},"trusted":true},"outputs":[],"source":["def sideBorder(img, d):\n","    h,w=img.shape[0:2]\n","    base_size=h+20,w+20,3\n","    if d == 1:\n","        base_size=h+20,w+20\n","    # make a 3 channel image for base which is slightly larger than target img\n","    base=np.zeros(base_size,dtype=np.uint8)\n","    if d == 1:\n","        cv2.rectangle(base,(0,0),(w+20,h+20),255,20) # really thick white rectangle\n","    else:\n","        cv2.rectangle(base,(0,0),(w+20,h+20),(255,255,255),20) # really thick white rectangle\n","    \n","    base[10:h+10,10:w+10]=img # this works\n","    return base"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def predict(img):\n","    return 1"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2022-03-25T11:01:57.714759Z","iopub.status.busy":"2022-03-25T11:01:57.714429Z","iopub.status.idle":"2022-03-25T11:02:31.715424Z","shell.execute_reply":"2022-03-25T11:02:31.714293Z","shell.execute_reply.started":"2022-03-25T11:01:57.714724Z"},"trusted":true},"outputs":[],"source":["def ImagetoSymbols(imgOriginal):    \n","    #imgOriginal = cv2.imread(\"./train_images/02937.jpg\")\n","    #img = imgOriginal.copy()\n","    imgOriginal = imutils.resize(imgOriginal, width=500)\n","    #ratio = img.shape[1] / float(imgOriginal.shape[1])\n","#     plt.imshow(imgOriginal)\n","#     plt.show()\n","    gray,thresh = preprocess(imgOriginal)\n","    # plt.imshow(gray,cmap='gray')\n","    # plt.show()\n","#     plt.imshow(thresh,cmap='gray')\n","#     plt.show()\n","\n","    #ClosedThresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3)))\n","    OpenedThresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7)))\n","\n","    minValue = np.min(OpenedThresh)\n","\n","    OpenedThresh[imgOriginal.shape[0]-4:imgOriginal.shape[0]-1, :] = minValue\n","    OpenedThresh[:, imgOriginal.shape[1]-4:imgOriginal.shape[1]-1] = minValue\n","    OpenedThresh[:, 0:3] = minValue\n","\n","\n","#     plt.imshow(OpenedThresh,cmap='gray')\n","#     plt.show()\n","\n","\n","\n","    #plt.imshow(ClosedThresh,cmap='gray')\n","    #plt.show()\n","    \n","\n","    cnts = cv2.findContours(OpenedThresh.copy(), cv2.RETR_EXTERNAL,\n","        cv2.CHAIN_APPROX_SIMPLE)\n","    cnts = imutils.grab_contours(cnts)\n","    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n","    # for c in cnts:\n","        # #print(c[0])\n","        # plt.scatter(c[:, 0, 0], -c[:, 0, 1])\n","        # plt.show()\n","    # np.array(cnts,dtype=np.int32).shape\n","    #print(cnts[-1])\n","    receiptCnt = contourApprox(imgOriginal, cnts)\n","    if len(receiptCnt) == 0:\n","        \n","        receiptCnt = [np.array([[[0,  0]], [[0, imgOriginal.shape[0]]],\n","         [[imgOriginal.shape[1], imgOriginal.shape[0]]], [[imgOriginal.shape[1], 0]]])]\n","    #print(receiptCnt)\n","\n","    numbers_cropped = []\n","    numbers_cropped_thresh = []\n","    letters_cropped = []\n","    letters_cropped_thresh = []\n","\n","\n","    if len(receiptCnt) == 2:\n","        x = 1\n","        avg1 = np.average(receiptCnt[0][:,0,0])\n","        avg2 = np.average(receiptCnt[1][:,0,0])\n","        if avg2 < avg1:\n","            receiptCnt[0],receiptCnt[1] = receiptCnt[1],receiptCnt[0] \n","\n","        final_img1 ,rgb_img1 = showApprox(imgOriginal, thresh, receiptCnt[0])\n","        final_img1 = sideBorder(final_img1, 1)\n","        rgb_img1 = sideBorder(rgb_img1, 3)\n","\n","\n","\n","        symbols_cropped, symbols_cropped_thresh = CutLetters(final_img1,rgb_img1, 2)\n","        for i in range(len(symbols_cropped)):\n","            numbers_cropped.append(symbols_cropped[i][0])\n","            numbers_cropped_thresh.append(symbols_cropped_thresh[i][0])\n","\n","        final_img1 ,rgb_img1 = showApprox(imgOriginal, thresh, receiptCnt[1])\n","        final_img1 = sideBorder(final_img1, 1)\n","        rgb_img1 = sideBorder(rgb_img1, 3)\n","\n","\n","\n","        symbols_cropped, symbols_cropped_thresh = CutLetters(final_img1,rgb_img1, 2)\n","        for i in range(len(symbols_cropped)):\n","            letters_cropped.append(symbols_cropped[i][0])\n","            letters_cropped_thresh.append(symbols_cropped_thresh[i][0])\n","\n","    \n","    else:\n","        avg = np.average(receiptCnt[0][:,0,0])\n","        final_img1 ,rgb_img1 = showApprox(imgOriginal, thresh, receiptCnt[0])\n","        final_img1 = sideBorder(final_img1, 1)\n","        rgb_img1 = sideBorder(rgb_img1, 3)\n","\n","        if final_img1.shape[1] < 280:\n","            if avg < final_img1.shape[1] / 2:\n","                symbols_cropped, symbols_cropped_thresh = CutLetters(final_img1,rgb_img1, 2)\n","                for i in range(len(symbols_cropped)):\n","                    numbers_cropped.append(symbols_cropped[i][0])\n","                    numbers_cropped_thresh.append(symbols_cropped_thresh[i][0])\n","            else:\n","                symbols_cropped, symbols_cropped_thresh = CutLetters(final_img1,rgb_img1, 2)\n","                for i in range(len(symbols_cropped)):\n","                    letters_cropped.append(symbols_cropped[i][0])\n","                    letters_cropped_thresh.append(symbols_cropped_thresh[i][0])\n","        else: \n","            symbols_cropped, symbols_cropped_thresh = CutLetters(final_img1,rgb_img1, 1)\n","            for i in range(len(symbols_cropped)):\n","                if symbols_cropped[i][1] < final_img1.shape[1] / 2:\n","                    numbers_cropped.append(symbols_cropped[i][0])\n","                    numbers_cropped_thresh.append(symbols_cropped_thresh[i][0])\n","                else:\n","                    letters_cropped.append(symbols_cropped[i][0])\n","                    letters_cropped_thresh.append(symbols_cropped_thresh[i][0])\n","    return numbers_cropped_thresh, letters_cropped_thresh\n","    #print(numbers_cropped_thresh)\n","    #for r in range(receiptCnt):\n","\n","\n","    #    final_img ,rgb_img= showApprox(imgOriginal, thresh, r)\n","    #    final_img = sideBorder(final_img, 1)\n","    #    rgb_img = sideBorder(rgb_img, 3)\n","\n","\n","    #    letters_cropped, letters_cropped_thresh = CutLetters(final_img,rgb_img, len(receiptCnt))\n","    #    for character in letters_cropped_thresh:\n","    #        charcater = np.array(character)\n","    #        plt.imshow(charcater)\n","    #        plt.show()\n","    #        #print(predict(img=character, model=model, labels=labels))\n","    #        print(predict(character))\n","    #      #print(final_img.shape[1])\n","    #      #CharacterContours(final_img)\n","\n","# plt.plot(cnts[0])\n","# plt.show()\n","\n","#cnts = skimage.measure.find_contours(thresh)\n","#cnts = sorted(cnts, reverse=True)\n","#cnts\n","\n","# for c in cnts:\n","#     # compute the bounding box of the contour and then use\n","#     # the bounding box to derive the aspect ratio\n","#     (x, y, w, h) = cv2.boundingRect(c)\n","#     ar = w / float(h)\n","#     if ar >= 2 and ar <= 10:\n","#         lpCnt = c\n","#         letter = gray[y:y + h, x:x + w]\n","#         roi = cv2.threshold(letter, 0, 255,\n","#                 cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n","#             # check to see if we should clear any foreground\n","#             # pixels touching the border of the image\n","#             # (which typically, not but always, indicates noise)\n","#         # display any debugging information and then break\n","#         # from the loop early since we have found the license\n","#         # plate region\n","#         # plt.plot(letter,cmap='gray')\n","#         # plt.show()\n","#         plt.plot(roi,cmap='gray')\n","#         plt.show()\n","#         print(\"****************\")\n","# print(roi)   "]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["imgOriginal = cv2.imread(f\"../input/testdata/test_images/{str(17).zfill(5)}.jpg\")\n","Nums, Chars = ImagetoSymbols(imgOriginal)\n","\n","# for number in Nums:\n","#     plt.imshow(number,cmap='gray')\n","#     plt.show()\n","# print(\"______________________________\")\n","# for letter in Chars:\n","#     plt.imshow(letter,cmap='gray')\n","#     plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}
